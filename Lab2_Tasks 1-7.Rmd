
---
title: "W271 Lab 2"
author: "Akin Akinlabi, Eduardo Gonzalez, Karanveer Lamba, Rui Sun, Victor Ndayambaje"
date: '`r Sys.Date()`'
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
# Loading Libraries
knitr::opts_chunk$set(echo = TRUE)
library(stargazer)
library(ggplot2)
library(tidyr)
library(httr)
library(jsonlite)
library(fredr)
library(lubridate)
library(forecast)
library(vars)
library(dplyr)
library(tidyverse)
library(zoo)
library(aTSA)
library(urca)
```

## Introduction

The Taylor Rule serves as a guideline for central banks, particularly the U.S. Federal Reserve, in adjusting interest rates based on inflation and output gaps. This study examines the empirical relevance of the Taylor Rule by analyzing quarterly U.S. macroeconomic data from 1980 to 2023. The dataset includes the Federal Funds Rate, an inflation measure based on Personal Consumption Expenditures (PCE) inflation, and the output gap, which measures the difference between actual and potential GDP. The data was sourced from FRED using the fredr package in R.. The primary objective is to examine the empirical relevance of the Taylor Rule and assess the potential for cointegration and error correction modeling in explaining Federal Reserve policy decisions.
This paper presents the data retrieval process, initial exploratory data analysis, and preprocessing steps. Key economic events, such as the Volcker disinflation in the 1980s, the 2008 Financial Crisis, and the COVID-19 pandemic, are contextualized within the dataset. Additionally, statistical techniques, including outlier detection, seasonality assessment, and stationarity testing, are applied to ensure the robustness of the analysis.

## Task 1: Data Retrieval and Initial EDA (Quarterly Frequency)
```{r Data Loading}

# I've used the fredr package in R to pull data - https://cran.r-project.org/web/packages/fredr/vignettes/fredr.html

# Set FRED API Key object
fredr_set_key("c58e9c0793ba6ec253e8588464dd1eca")

# Set date range
start_date <- as.Date("1980-01-01")
end_date <- Sys.Date()

# Download Federal Funds Rate (FEDFUNDS)
fed_funds <- fredr(series_id = "FEDFUNDS", observation_start = start_date, frequency = "q") %>%
  select(date, fed_rate = value)

# Download PCE Price Index (PCEPI) for Inflation
pcepi <- fredr(series_id = "PCEPI", observation_start = start_date, frequency = "q") %>%
  select(date, pce_index = value)

# Download Real GDP (GDPC1)
real_gdp <- fredr(series_id = "GDPC1", observation_start = start_date, frequency = "q") %>%
  select(date, real_gdp = value)

# Download Potential GDP (GDPPOT)
potential_gdp <- fredr(series_id = "GDPPOT", observation_start = start_date, frequency = "q") %>%
  select(date, potential_gdp = value)

```

``` {r create inflation series}

pcepi <- pcepi %>%
  arrange(date) %>%
  mutate(inflation = round((pce_index / lag(pce_index) - 1) * 100, 2))

```

``` {r create output gap series}

output_gap <- real_gdp %>%
  inner_join(potential_gdp, by = "date") %>%
  mutate(output_gap = ((real_gdp - potential_gdp) / potential_gdp) * 100)

```

``` {r merge data}

df <- fed_funds %>%
  inner_join(pcepi, by = "date") %>%
  inner_join(output_gap, by = "date")
  
```

``` {r plot series}

# Federal Funds Rate over time
ggplot(df, aes(x = date, y = fed_rate)) +
  geom_line(color = "blue") +
  labs(title = "Federal Funds Rate Over Time", x = "Year", y = "Fed Funds Rate (%)") +
  scale_x_date(date_breaks = "3 years", date_labels = "%Y") +  # Set 2-year gaps on X-axis
  theme_minimal()

# Inflation over time
ggplot(df, aes(x = date, y = inflation)) +
  geom_line(color = "red") +
  labs(title = "Inflation Rate Over Time", x = "Year", y = "Inflation (%)") +
  scale_x_date(date_breaks = "3 years", date_labels = "%Y") +  # Set 2-year gaps on X-axis
  theme_minimal()

# Output Gap over time
ggplot(df, aes(x = date, y = output_gap)) +
  geom_line(color = "green") +
  labs(title = "Output Gap Over Time", x = "Year", y = "Output Gap (%)") +
  scale_x_date(date_breaks = "3 years", date_labels = "%Y") +  # Set 2-year gaps on X-axis
  theme_minimal()
```
``` {r summary statistics}

summary(df)

```

This study examines the empirical relevance of the Taylor Rule by analyzing quarterly U.S. macroeconomic data from 1980 to 2023. The dataset includes the Federal Funds Rate, an inflation measure based on Personal Consumption Expenditures (PCE) inflation, and the output gap, which measures the difference between actual and potential GDP. The data was sourced from FRED using the fredr package in R.
The Federal Funds Rate has exhibited significant fluctuations over the past four decades. During the 1980s, interest rates exceeded 15%, reflecting the Federal Reserve’s aggressive tightening to combat inflation. In the 2000s, rates remained relatively stable but dropped sharply following the 2008 Financial Crisis, when the Fed cut rates to near-zero to stimulate economic activity. Similarly, in 2020, the Fed once again implemented near-zero interest rates in response to the COVID-19 pandemic. However, starting in 2022, a rapid series of rate hikes occurred as the Fed sought to control post-pandemic inflationary pressures.
Inflation trends reflect these monetary policy adjustments. The 1980s saw persistently high inflation, which gradually declined due to restrictive monetary policy. A brief period of deflation occurred during the 2008 Financial Crisis, with inflation falling below zero. However, in the 2020s, inflation spiked dramatically due to post-pandemic supply chain disruptions, stimulus measures, and demand surges.
The output gap provides further insights into economic cycles. Large negative output gaps, indicating recessions, were observed in the 1980s, early 1990s, and during the 2008 Financial Crisis. The COVID-19 pandemic caused the steepest drop in the output gap, reflecting an abrupt economic contraction, but a strong recovery followed as the economy reopened.

## Task 2: Preprocessing 

```{r frequency alignment}
df$quarter <- as.yearqtr(df$date)  # Create a quarter column
df_quarterly <- aggregate(cbind(fed_rate, pce_index, inflation, real_gdp, potential_gdp, output_gap) ~ quarter, data = df, FUN = mean)
summary(df_quarterly)
```

```{r outlier detection and treatment}
# Set percentile thresholds for Winsorizing (1st and 99th percentile)
lower_percentile <- 0.01
upper_percentile <- 0.99

# Function to Winsorize a variable
winsorize <- function(x, lower_percentile, upper_percentile) {
  lower_cutoff <- quantile(x, lower_percentile)
  upper_cutoff <- quantile(x, upper_percentile)
  
  # Cap values at the 1st and 99th percentiles
  x[x < lower_cutoff] <- lower_cutoff
  x[x > upper_cutoff] <- upper_cutoff
  
  return(x)
}

# Apply Winsorizing to all variables
df_quarterly$fed_rate <- winsorize(df_quarterly$fed_rate, lower_percentile, upper_percentile)
df_quarterly$pce_index <- winsorize(df_quarterly$pce_index, lower_percentile, upper_percentile)
df_quarterly$inflation <- winsorize(df_quarterly$inflation, lower_percentile, upper_percentile)
df_quarterly$real_gdp <- winsorize(df_quarterly$real_gdp, lower_percentile, upper_percentile)
df_quarterly$potential_gdp <- winsorize(df_quarterly$potential_gdp, lower_percentile, upper_percentile)
df_quarterly$output_gap <- winsorize(df_quarterly$output_gap, lower_percentile, upper_percentile)
```

Since some of the original datasets were reported at a monthly frequency, they were converted to quarterly frequency using the as.yearqtr() function in R. Monthly observations were aggregated using the aggregate() function to ensure consistency across all variables.
The exploratory analysis revealed extreme fluctuations in interest rates, inflation, and the output gap, suggesting potential outliers. Instead of removing these data points, Winsorizing was applied to cap extreme values at the 99th and 1st percentiles. This approach retains all observations while minimizing the impact of extreme values that could distort statistical analysis.
To determine whether seasonal adjustment was necessary, the nsdiffs() function from the forecast package was used to test for seasonal differencing. Additionally, STL decomposition (stl()) was applied to break down the time series into trend, seasonal, and residual components. The seasonal component showed no strong repetitive patterns, and the test result indicated that seasonal differencing was not required. Consequently, no seasonal adjustment was applied to the dataset.

```{r seasonal adjustment}
# Seasonal plot of real_gdp
ggplot(df_quarterly, aes(x = quarter, y = real_gdp)) +
  geom_line() +
  facet_wrap(~ factor(month(quarter)), scales = "free_y") +
  labs(title = "Seasonal Plot of Real GDP", x = "Quarter", y = "Real GDP")

# Convert the data to a time series object (quarterly data)
ts_data <- ts(df_quarterly$real_gdp, frequency = 4)

# Test for seasonal differencing
seasonality_test <- nsdiffs(ts_data)

# Print the result
print(seasonality_test)

# Apply STL decomposition
decomp <- stl(ts_data, s.window = "periodic")

# Plot the decomposition to visualize the seasonal component
plot(decomp)
```

## Task 3: Stationarity Testing & Potential Structural Breaks

The Augmented Dickey-Fuller tests for unit roots were conducted with three different regression models: none, drift, and trend. The trend model, which included both a constant and a linear trend, had a test statistic of -2.18, also showing no significant evidence of stationarity, with a p-value of 0.05779. The second model (drift) included a constant, and the test statistic of 1.17 showed no significant evidence of stationarity, with a p-value of 0.2194. Finally, the test statistic was 5.44, which is significant at the 1% level, suggesting the series is stationary. This progression from the most general model (trend) to the simplest model (none) supports the conclusion that the series is stationary.

```{r stationarity with structural break}
ts_quarterly <- ts(df_quarterly$real_gdp, start = c(1980, 1), frequency = 4)

# ADF test with constant and trend, specifying 4 lags
adf_trend <- ur.df(ts_quarterly, type = "trend", lags = 4)
summary(adf_trend)

# ADF test with constant (drift), specifying 4 lags
adf_drift <- ur.df(ts_quarterly, type = "drift", lags = 4)
summary(adf_drift)

# ADF test with no constant or trend, specifying 4 lags
adf_none <- ur.df(ts_quarterly, type = "none", lags = 4)  # Specify a valid number of lags
summary(adf_none)
```
## Task 4

```{r Estimating the Basic Taylor Rule (OLS)}

# Assuming df_quarterly is your dataframe and it has a column named 'inflation'
df_quarterly <- df_quarterly %>%
  mutate(inflation_gap = inflation - 2)

# Add a second predictor: lagged value of the time series
df_quarterly <- df_quarterly %>%
  mutate(lagged_inflation = lag(inflation, order_by = quarter))

train_set <- df_quarterly %>% filter(quarter < '2022 Q4')
test_set <- df_quarterly %>% filter(quarter >= '2022 Q4')

# Remove NA values
train_set <- na.omit(train_set)
test_set <- na.omit(test_set)

# Fit the ols with lag model
ols_model <- glm(fed_rate ~ lagged_inflation + inflation_gap + output_gap , data = train_set)

# Fit the ols without lag model
ols_model <- glm(fed_rate ~ inflation_gap + output_gap , data = train_set)

# Predict on the test set
predictions <- predict(ols_model, newdata = test_set)

# Calculate the residuals
residuals <- residuals(ols_model)

# Summarize the model
summary(ols_model)

# Predict on the training set
train_set$Predicted <- predict(ols_model, newdata = train_set)

# Predict on the test set
test_set$Predicted <- predict(ols_model, newdata = test_set)

# Calculate the residuals
residuals <- residuals(ols_model)

# Calculate the RMSE
rmse <- sqrt(mean((train_set$fed_rate - train_set$Predicted)^2))
print(paste("In Sample: Root Mean Squared Error (RMSE):", rmse))
rmse <- sqrt(mean((test_set$fed_rate - test_set$Predicted)^2))
print(paste("Out of Sample: Root Mean Squared Error (RMSE):", rmse))



# Plot the time series and the fitted linear model for the training set
ggplot(train_set, aes(x = quarter)) +
  geom_line(aes(y = fed_rate), color = "black") +
  geom_line(aes(y = Predicted), color = "blue") +
  labs(title = "Linear Model Fit to Time Series Data (Training Set)",
       x = "Time",
       y = "Fed Rate")

# Plot the time series and the fitted linear model for the training set
ggplot(test_set, aes(x = quarter)) +
  geom_line(aes(y = fed_rate), color = "black") +
  geom_line(aes(y = Predicted), color = "blue") +
  labs(title = "Linear Model Fit to Time Series Data (Training Set)",
       x = "Time",
       y = "Fed Rate")

# Calculate the residuals
residuals <- residuals(ols_model)

par(mfrow=c(2,2))

# Plot the residuals using an ACF plot
acf(residuals, main = "ACF of Residuals")
pacf(residuals, main = "PACF of Residuals")
# Plot the histogram of residuals with a normal distribution curve
hist(residuals, breaks = 10, probability = TRUE, main = "Histogram of Residuals with Normal Curve", xlab = "Residuals")
curve(dnorm(x, mean = mean(residuals), sd = sd(residuals)), col = "blue", lwd = 2, add = TRUE, yaxt = "n")
```
According to the https://www.federalreserve.gov/economy-at-a-glance-inflation-pce.htm target inflation is 2%

1. At a parameter alpha0 = 1.89988 and p_value < .05, interest moves more than one for one with inflation. 
Although it does not agree with Taylor's rule, it is worth noting that this model is an oversimplifcation of complex/unpredictable economic variables such as COVID-19
2. In sample RMSE yields 3.27043042498184. 3 percent in interest rates is a not a good sign for the model.
The plot shows that COVID-19 years had a huge impact in the residuals. It may be worth treating COVID-19 data to better the model. Also worth noting is the ACF plot indicates some degree in autocorrelation of the residuals.
3. It is worth mentioning that this is a good prediction of the model as the RSME = 1.37524946670628 is lower in the test set. Evaluating the plot shows the residuals are lessened in comparison to the test data

## Task 5

```{r Cointegration and Error Correction Model (ECM)}
# Engle-Granger Cointegration Test
long_run_model <- lm(fed_rate ~ inflation_gap + output_gap, data = train_set)
summary(long_run_model)

# Extract residuals from long-run model
train_set <- train_set %>%
  mutate(residuals = residuals(long_run_model))

# ADF test on residuals (Engle-Granger test)
adf_test_residuals <- ur.df(train_set$residuals, type = "none", lags = 4)
summary(adf_test_residuals)

# Error Correction Model (ECM)
# Compute first differences and lagged residuals
train_set <- train_set %>%
  mutate(
    d_fed_rate = c(NA, diff(fed_rate, lag = 1)),  # Prepend NA to match length
    d_inflation_gap = c(NA, diff(inflation_gap, lag = 1)),
    d_output_gap = c(NA, diff(output_gap, lag = 1)),
    lagged_residuals = lag(residuals, n = 1)
  ) %>%
  na.omit()  # Remove first-row NA values

# Fit the ECM model
ecm_model <- lm(d_fed_rate ~ d_inflation_gap + d_output_gap + lagged_residuals, data = train_set)
summary(ecm_model)

test_set <- test_set %>%
  mutate(
    residuals = predict(long_run_model, newdata = test_set) - test_set$fed_rate
  )

# ECM Forecast Performance on Test Set
test_set <- test_set %>%
  mutate(
    d_fed_rate = c(NA, diff(fed_rate, lag = 1)),
    d_inflation_gap = c(NA, diff(inflation_gap, lag = 1)),
    d_output_gap = c(NA, diff(output_gap, lag = 1)),
    lagged_residuals = lag(residuals, n = 1)
  ) %>%
  na.omit()

# Predict using ECM model
test_set$ECM_Predicted <- predict(ecm_model, newdata = test_set)

# Compute RMSE for ECM model
rmse_ecm_train <- sqrt(mean(residuals(ecm_model)^2))
rmse_ecm_test <- sqrt(mean((test_set$fed_rate - test_set$ECM_Predicted)^2))

print(paste("ECM In-Sample RMSE:", rmse_ecm_train))
print(paste("ECM Out-of-Sample RMSE:", rmse_ecm_test))

# Plot actual vs. predicted (ECM)
ggplot(test_set, aes(x = quarter)) +
  geom_line(aes(y = fed_rate), color = "black") +
  geom_line(aes(y = ECM_Predicted), color = "blue") +
  labs(title = "ECM Model Predictions vs. Actual Fed Funds Rate",
       x = "Quarter",
       y = "Fed Funds Rate (%)")
```
The results shows that the basic Taylor Rule has some explanatory power but lacks a strong fit. The inflation gap is highly significant, with a coefficient of 4.38, meaning that for every 1% increase in the inflation gap, the Fed Funds Rate is expected to rise by about 4.38 percentage points. However, the output gap is statistically insignificant, p = 0.867, suggesting it has little influence on interest rate decisions in this model. The R² of 0.27 indicates that the model explains only 27% of the variation in interest rates, implying that other factors influence Fed policy.
The Augmented Dickey-Fuller test on the residuals suggests a weak rejection of the unit root hypothesis, test statistic = -2.14, above the 5% critical value of -1.95. This indicates some level of co-integration between the Fed Funds Rate, inflation gap, and output gap, but it is not particularly strong.
The Error Correction Model results show that short-term changes in the output gap significantly impact interest rate changes, p < 0.001, whereas short-term changes in the inflation gap do not, p = 0.83. The lagged residuals coefficient, -0.05199, p < 0.001, confirms that there is an adjustment process towards the long-run equilibrium, but the speed of correction is slow. The ECM in-sample RMSE (0.55) suggests a good fit within the training data, but the out-of-sample RMSE (5.11) is much higher, indicating poor forecasting performance.
The plot confirms this issue, as the ECM predictions (blue line) are consistently lower than the actual Fed Funds Rate (black line), meaning the model significantly under predicts interest rates. This could be due to the poor explanatory power of the output gap, weak co-integration, or changes in Fed policy not captured by the Taylor Rule framework.

## Task 6

This task is about residual Modeling & forecasting and the goal is to evaluate the Taylor Rule and ECM models, determine which is better, and apply ARIMA residual correction if necessary. We compare their forecasting accuracy using RMSE.

### Compare Taylor Rule Model vs. ECM

Before applying ARIMA, we first compare the Taylor Rule model and the ECM to determine which model performs better

#### 1. Compute RMSE for Taylor Rule

```{r}
# Predict on test set using Taylor Rule model
test_set$predicted_fed_rate_taylor <- predict(ols_model, newdata = test_set)

# Compute RMSE for Taylor Rule
rmse_taylor <- sqrt(mean((test_set$fed_rate - test_set$predicted_fed_rate_taylor)^2, na.rm = TRUE))
print(paste("Taylor Rule RMSE:", round(rmse_taylor, 3)))


```
#### 2. Compute RMSE for ECM

```{r}
# Predict ECM on test set
test_set$ECM_Predicted <- predict(ecm_model, newdata = test_set)

# Compute RMSE for ECM
rmse_ecm <- sqrt(mean((test_set$fed_rate - test_set$ECM_Predicted)^2, na.rm = TRUE))
print(paste("ECM RMSE:", round(rmse_ecm, 3)))

```
#### 3. Decision - Which Model is Better?

```{r}
if (rmse_ecm < rmse_taylor) {
  print("ECM performs better than Taylor Rule. Proceeding with ECM for ARIMA modeling.")
  selected_model <- ecm_model
  test_set$Final_Predicted <- test_set$ECM_Predicted
} else {
  print("Taylor Rule performs better. No need for ARIMA on ECM residuals.")
  selected_model <- ols_model
  test_set$Final_Predicted <- test_set$predicted_fed_rate_taylor
}

```
### Extract Residuals from Taylor Rule Model

```{r}
# Extract residuals from the Taylor Rule model
taylor_residuals <- residuals(ols_model)  

# Convert residuals into a time series object
ts_residuals <- ts(taylor_residuals, start = c(1980,1), frequency = 4)

# Plot residuals to check for patterns
autoplot(ts_residuals) +
  ggtitle("Residuals of the Taylor Rule Model") +
  xlab("Year") +
  ylab("Residuals")
```
The residuals plot shows the difference between the actual and predicted Fed Funds Rate from the Taylor Rule regression. There are periods of high residual volatility, particularly in the 1980s and 2008, indicating times when the model struggled to capture interest rate movements. The downward trend in recent years suggests potential structural changes in monetary policy.


### Identify the Best ARIMA Model for Taylor Rule Residuals

We check for residual autocorrelation and identify the best ARIMA model.
```{r}
# Automatically select best ARIMA model
arima_residuals_model <- auto.arima(ts_residuals)

# Display ARIMA model summary
summary(arima_residuals_model)

# Check ACF and PACF plots
par(mfrow=c(1,2))
acf(ts_residuals, main="ACF of Residuals")
pacf(ts_residuals, main="PACF of Residuals")

```
The Autocorrelation Function (ACF) shows significant persistence in residuals, indicating that past errors influence future errors. The Partial Autocorrelation Function (PACF) suggests an ARIMA model with an MA(1) and seasonal AR(2) structure is appropriate. This confirms that the Taylor Rule residuals exhibit serial correlation and require correction.

### Forecast Residuals Using ARIMA

We forecast residuals for the next 8 quarters (2023Q1–2024Q4).

```{r}
# Forecast residuals for 8 future quarters (2023Q1–2024Q4)
residual_forecast <- predict(arima_residuals_model, n.ahead = 8)

# Convert forecast to a data frame
residual_forecast_df <- data.frame(
  quarter = seq(max(test_set$quarter) + 0.25, by = 0.25, length.out = 8),
  residual_forecast = residual_forecast$pred
)

# Plot forecasted residuals
ggplot(residual_forecast_df, aes(x = quarter, y = residual_forecast)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(title = "Forecasted Residuals from ARIMA Model",
       x = "Year", y = "Residuals") +
  theme_minimal()


```

The selected ARIMA(0,1,1)(2,0,0)[4] model includes a first-order moving average (MA(1)) and two seasonal autoregressive terms (SAR(2)), capturing quarterly seasonality. The forecasted residuals exhibit fluctuations but no clear trend, suggesting that the Taylor Rule model misses some cyclical patterns but does not show strong mean reversion. Peaks and troughs in the residuals indicate that some systematic variation remains unexplained. The AIC (640.9) and BIC (653.4) suggest a reasonable but not perfect fit, meaning there may be potential for improvement by adjusting seasonal terms or investigating structural breaks.

### Combine ARIMA and Taylor Rule Predictions

We now adjust the Taylor Rule predictions by adding forecasted residuals.

```{r}
# Forecast Taylor Rule model for test period
test_set$predicted_fed_rate_taylor <- predict(ols_model, newdata = test_set)

# Ensure ARIMA forecast matches test period length
residual_forecast_values <- residual_forecast$pred[1:nrow(test_set)]  # Extract the right number of values

# Add ARIMA residual forecast to Taylor Rule predictions
test_set$predicted_fed_rate_combined <- test_set$predicted_fed_rate_taylor + residual_forecast_values

# Plot the comparison
ggplot(test_set, aes(x = quarter)) +
  geom_line(aes(y = fed_rate, color = "Actual Fed Rate"), linewidth = 1) +  # Change `size` to `linewidth`
  geom_line(aes(y = predicted_fed_rate_taylor, color = "Taylor Rule Prediction"), linetype = "dashed", linewidth = 1) +
  geom_line(aes(y = predicted_fed_rate_combined, color = "Taylor + ARIMA"), linetype = "dotted", linewidth = 1) +
  labs(title = "Actual vs. Predicted Fed Funds Rate",
       x = "Year", y = "Interest Rate (%)") +
  scale_color_manual(name = "Legend",
                     values = c("Actual Fed Rate" = "black",
                                "Taylor Rule Prediction" = "blue",
                                "Taylor + ARIMA" = "red")) +
  theme_minimal()

```
The Taylor Rule model (blue dashed line) follows the actual Fed Funds Rate (black line) relatively well, though it slightly underpredicts the rate in some quarters. However, the Taylor + ARIMA model (red dotted line) significantly underestimates the Fed Funds Rate, even producing negative interest rate forecasts, which are economically implausible. This indicates that ARIMA residual correction introduces excessive downward adjustments, worsening the predictive accuracy rather than improving it. The poor performance of Taylor + ARIMA suggests that the residuals may not follow a purely stochastic process or that important structural changes in monetary policy are not being captured effectively.

### Evaluate Forecast Accuracy

To determine whether the Taylor Rule + ARIMA approach improves forecasting, we compare Root Mean Squared Error (RMSE) vs. Taylor Rule + ARIMA:

```{r}
# Compute RMSE for Taylor Rule alone
rmse_taylor <- sqrt(mean((test_set$fed_rate - test_set$predicted_fed_rate_taylor)^2, na.rm = TRUE))

# Compute RMSE for Taylor Rule + ARIMA
rmse_combined <- sqrt(mean((test_set$fed_rate - test_set$predicted_fed_rate_combined)^2, na.rm = TRUE))

# Print RMSE results
print(paste("Taylor Rule RMSE:", round(rmse_taylor, 3)))
print(paste("Taylor + ARIMA RMSE:", round(rmse_combined, 3)))

# Check which model performs better
if (rmse_combined < rmse_taylor) {
  print("Taylor Rule + ARIMA improves forecasting accuracy!")
} else {
  print("Taylor Rule alone performs better.")
}

```
The Taylor Rule model alone achieves a significantly lower RMSE (1.261) compared to the Taylor + ARIMA model (5.845), indicating that applying ARIMA to the residuals actually worsened forecast accuracy. Instead of reducing errors, the ARIMA correction introduced excessive downward adjustments, likely due to overfitting or an inability to capture the underlying structural dynamics of the Fed Funds Rate. This suggests that the residuals from the Taylor Rule model may not follow a simple stochastic pattern and that monetary policy adjustments may not be effectively modeled using this approach.

**Conclusion**

The Taylor Rule model alone remains the better predictor, as it has a lower RMSE (1.261 vs. 5.845) and aligns more closely with actual interest rates. The attempt to refine predictions using ARIMA did not improve accuracy and instead led to excessive deviation from actual values, particularly with unrealistic negative forecasts. This outcome suggests that ARIMA correction is not suitable in this case, and alternative approaches such as Vector Autoregression (VAR) or regime-switching models should be explored to better account for the complexities in Fed policy decisions and economic fluctuations.


## Task 7

### Goals for this task

#### VAR Model

- Aim to capture the dynamic relationships between the federal funds rate, output gap, and inflation gap by fitting a Vector Autoregression (VAR) model. The goal is to understand how these variables influence each other over time.

#### Forecasting

- Use the fitted VAR model to generate multi-step forecasts for the federal funds rate and evaluate its predictive performance by comparing RMSE values for both the training and test periods.

#### Granger Causality

- Investigate whether the inflation gap and output gap provide significant predictive information for changes in the federal funds rate. Additionally, analyze how shocks in these variables influence the federal funds rate through impulse response analysis.


```{r VAR Model and IRF}

# Select relevant columns and ensure correct data types
var_data <- train_set %>%
  dplyr::select(fed_rate, output_gap, inflation_gap) %>%
  mutate(across(c(fed_rate, output_gap, inflation_gap), as.numeric)) %>%
  drop_na()

# Select optimal lag length
var_lag_select <- VARselect(var_data, lag.max = 4, type = "none")

# Extract optimal lag length
optimal_lag <- var_lag_select$selection[["AIC(n)"]]

# Fit the VAR model
var_model <- VAR(var_data, p = optimal_lag, type = "none")

summary(var_model)

# Extract the actual and the fitted values for the training period
actual_train_fedfunds <- train_set$fed_rate
fitted_train_var <- as.data.frame(fitted(var_model))$fed_rate

# Forecasting out-of-sample (test period)
test_forecast <- predict(var_model, n.ahead = nrow(test_set))

# Extracting the forecasted values for the test period from the VAR forecast result
test_forecast_fedfunds <- test_forecast$fcst$fed_rate[, "fcst"]

# Extract the actual values for the test period
actual_test_fedfunds <- test_set$fed_rate

# Calculating Train and Test RMSE for the VAR model
train_rmse_var <- sqrt(mean((actual_train_fedfunds - fitted_train_var)^2, na.rm = TRUE))
test_rmse_var <- sqrt(mean((actual_test_fedfunds - test_forecast_fedfunds)^2, na.rm = TRUE))

cat("Train RMSE (VAR, fedfunds):", train_rmse_var, "\n")
cat("Test RMSE (VAR, fedfunds):", test_rmse_var, "\n")

# Granger Causality Test
# Test whether inflation gap and output gap Granger-cause the federal funds rate
granger_causality_inflation <- causality(var_model, cause = "inflation_gap")$Granger
granger_causality_output_gap <- causality(var_model, cause = "output_gap")$Granger

print(granger_causality_inflation)
print(granger_causality_output_gap)

# Impulse Response Functions
irf_result <- irf(var_model, impulse = "inflation_gap", response = "fed_rate", n.ahead = 8, boot = TRUE, ci = 0.95)
plot(irf_result)

cat("RMSE Values:", "\n", "RMSE Taylor", rmse_taylor, "\n")
cat("RMSE ECM", rmse_ecm_test, "\n")
cat("RMSE Combined", rmse_combined, "\n")

```

### Summary of the VAR model

- Stability and Model Fit

  - Roots of the characteristic polynomial:
    
    - All roots are less than 1, confirming the system's stability — a key condition for a valid VAR model.

- R-squared values:
  
  - fed_rate: 0.99 (excellent fit)
  
  - output_gap: 0.8795 (strong fit)
  
  - inflation_gap: 0.9501 (excellent fit)

  These high R-squared values suggest the model captures the data's variance well.

- Key Findings for Each Equation

- Equation for fed_rate

  - Significant predictors:
  
    - fed_rate.l1 (positive and highly significant) — suggests strong persistence in the federal funds rate.
  
    - fed_rate.l2 (negative and significant) — indicates a partial correction effect after lag 1.
    
    - output_gap.l3 (negative and significant) — suggests a delayed effect where an increase in the output gap reduces the fed rate later.
  
  - Insignificant predictors:
  
    - inflation_gap terms are not significant, indicating minimal short-term impact on the fed rate.

- Equation for output_gap

  - Significant predictors:

    - output_gap.l1 (positive and highly significant) — shows strong persistence in the output gap itself.

  - Insignificant predictors:

    - None of the fed_rate or inflation_gap terms are statistically significant (ignoring the significance of fed_rate.l1 at alpha level 0.1, since it is not strong enough to report), indicating limited direct impact from these variables.

- Equation for inflation_gap

  - Significant predictors:

    - inflation_gap.l1 and inflation_gap.l3 (both positive and highly significant) — indicate strong persistence in inflation dynamics with delayed feedback effects.
  
  - Insignificant predictors:

    - Neither fed_rate nor output_gap shows meaningful influence.

- Residual Analysis

  - Residual Correlation Matrix shows some correlation between fed_rate and output_gap (0.34) and between output_gap and inflation_gap (0.34), indicating mild interdependence.
These correlations align with economic theory, where monetary policy and economic output tend to influence each other.

### RMSE Interpretation

The RMSE of the VAR model performs better than the ECM model (5.07), and the combine Taylor Rule + ARIMA model (5.84). However, the simple Taylor model still has the best RMSE making it the most suitable model for forecasting fed_rate.

### Summary of Granger Test Results

- Inflation Gap $(π_t - π^*)$: There is no significant Granger causality from the inflation gap to the federal funds rate. This suggests that past values of the inflation gap do not provide useful information for predicting future values of the federal funds rate, beyond what is already included in the lagged values in the VAR model.

- Output Gap: Similarly, there is no significant Granger causality from the output gap to the federal funds rate. This suggests that past values of the output gap do not provide additional predictive power for the future values of the federal funds rate in the context of the VAR model.