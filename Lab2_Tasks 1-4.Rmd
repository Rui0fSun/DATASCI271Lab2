
---
title: "W271 Lab 2"
author: "Akin Akinlabi, Eduardo Gonzalez, Karanveer Lamba, Rui Sun, Victor Ndayambaje"
output: pdf_document
date: '`r Sys.Date()`'
---

```{r setup, include=FALSE}
# Loading Libraries
knitr::opts_chunk$set(echo = TRUE)
library(stargazer)
library(ggplot2)
library(dplyr)
library(tidyr)
library(httr)
library(jsonlite)
library(fredr)
library(lubridate)
```

## Task 1: Data Retrieval and Initial EDA (Quarterly Frequency)
```{r Data Loading}

# I've used the fredr package in R to pull data - https://cran.r-project.org/web/packages/fredr/vignettes/fredr.html

# Set FRED API Key object
fredr_set_key("c58e9c0793ba6ec253e8588464dd1eca")

# Set date range
start_date <- as.Date("1980-01-01")
end_date <- Sys.Date()

# Download Federal Funds Rate (FEDFUNDS)
fed_funds <- fredr(series_id = "FEDFUNDS", observation_start = start_date, frequency = "q") %>%
  select(date, fed_rate = value)

# Download PCE Price Index (PCEPI) for Inflation
pcepi <- fredr(series_id = "PCEPI", observation_start = start_date, frequency = "q") %>%
  select(date, pce_index = value)

# Download Real GDP (GDPC1)
real_gdp <- fredr(series_id = "GDPC1", observation_start = start_date, frequency = "q") %>%
  select(date, real_gdp = value)

# Download Potential GDP (GDPPOT)
potential_gdp <- fredr(series_id = "GDPPOT", observation_start = start_date, frequency = "q") %>%
  select(date, potential_gdp = value)

```

``` {r create inflation series}

pcepi <- pcepi %>%
  arrange(date) %>%
  mutate(inflation = round((pce_index / lag(pce_index) - 1) * 100, 2))

```

``` {r create output gap series}

output_gap <- real_gdp %>%
  inner_join(potential_gdp, by = "date") %>%
  mutate(output_gap = ((real_gdp - potential_gdp) / potential_gdp) * 100)

```

``` {r merge data}

df <- fed_funds %>%
  inner_join(pcepi, by = "date") %>%
  inner_join(output_gap, by = "date")
  
```

``` {r plot series}

# Federal Funds Rate over time
ggplot(df, aes(x = date, y = fed_rate)) +
  geom_line(color = "blue") +
  labs(title = "Federal Funds Rate Over Time", x = "Year", y = "Fed Funds Rate (%)") +
  scale_x_date(date_breaks = "3 years", date_labels = "%Y") +  # Set 2-year gaps on X-axis
  theme_minimal()

# Inflation over time
ggplot(df, aes(x = date, y = inflation)) +
  geom_line(color = "red") +
  labs(title = "Inflation Rate Over Time", x = "Year", y = "Inflation (%)") +
  scale_x_date(date_breaks = "3 years", date_labels = "%Y") +  # Set 2-year gaps on X-axis
  theme_minimal()

# Output Gap over time
ggplot(df, aes(x = date, y = output_gap)) +
  geom_line(color = "green") +
  labs(title = "Output Gap Over Time", x = "Year", y = "Output Gap (%)") +
  scale_x_date(date_breaks = "3 years", date_labels = "%Y") +  # Set 2-year gaps on X-axis
  theme_minimal()
```
``` {r summary statistics}

summary(df)

```

### Plot Interpretation

#### Federal Funds Rate (Top Panel - Blue Line)

- 1980s: Interest rates were at historically high levels (above 15%) due to the Federal Reserve’s aggressive tightening to combat inflation.

- 2000s: The rate remained relatively stable before being cut sharply after the 2008 Financial Crisis, when the Fed reduced rates to near-zero to stimulate the economy.

- 2020: Another near-zero rate policy followed during the COVID-19 pandemic to counter economic downturns.

- 2022-Present: A rapid rate hike is visible, reflecting the Fed’s response to post-pandemic inflation.

#### Inflation Rate (Middle Panel - Red Line)

- 1980s: Inflation started high but steadily declined after the Volcker-led Fed raised interest rates aggressively.

- 2008 Financial Crisis: There was a brief period of deflation (inflation dropping below zero).

- 2020s: A sharp spike in inflation post-COVID due to supply chain disruptions, stimulus spending, and demand recovery.

#### Output Gap (Bottom Panel - Green Line)

- 1980s-1990s: Large negative output gaps were seen during recessions, indicating economic contractions.

- 2008-2009 Financial Crisis: A sharp drop in the output gap occurred, reflecting a deep recession.

- 2020 (COVID-19 Recession): The steepest drop in output gap, followed by a strong recovery.

## Task 2: Preprocessing 

All datasets are set to be quarterly using as.yearqtr(date), and are aggregated from the monthly values to quarterly with the aggregate function.

```{r frequency alignment}
library(zoo)
df$quarter <- as.yearqtr(df$date)  # Create a quarter column
df_quarterly <- aggregate(cbind(fed_rate, pce_index, inflation, real_gdp, potential_gdp, output_gap) ~ quarter, data = df, FUN = mean)
summary(df_quarterly)
```

From task 1, the three plots show extreme spikes, indicating outliers. Winsorizing is a method to cap extreme outliers. Instead of removing outliers, in this case to retain all data points but to modify extreme values and their influence, any data point above the 99th percentile are capped at the 99th percentile value, and any data point below the 1st percentile are capped at the 1st percentile value.

```{r outlier detection and treatment}
# Set percentile thresholds for Winsorizing (1st and 99th percentile)
lower_percentile <- 0.01
upper_percentile <- 0.99

# Function to Winsorize a variable
winsorize <- function(x, lower_percentile, upper_percentile) {
  lower_cutoff <- quantile(x, lower_percentile)
  upper_cutoff <- quantile(x, upper_percentile)
  
  # Cap values at the 1st and 99th percentiles
  x[x < lower_cutoff] <- lower_cutoff
  x[x > upper_cutoff] <- upper_cutoff
  
  return(x)
}

# Apply Winsorizing to all variables
df_quarterly$fed_rate <- winsorize(df_quarterly$fed_rate, lower_percentile, upper_percentile)
df_quarterly$pce_index <- winsorize(df_quarterly$pce_index, lower_percentile, upper_percentile)
df_quarterly$inflation <- winsorize(df_quarterly$inflation, lower_percentile, upper_percentile)
df_quarterly$real_gdp <- winsorize(df_quarterly$real_gdp, lower_percentile, upper_percentile)
df_quarterly$potential_gdp <- winsorize(df_quarterly$potential_gdp, lower_percentile, upper_percentile)
df_quarterly$output_gap <- winsorize(df_quarterly$output_gap, lower_percentile, upper_percentile)
```

The ggplot2 package is used to visualize the real GDP over time, allowing for the identification of any potential seasonal variation. To further assess seasonality, the nsdiffs function from the forecast package is used to test for the need for seasonal differencing. STL decomposition is applied using the stl() function, which separates the time series into its trend, seasonal, and residual components. The seasonal component is extracted to assess potential seasonal effects. Based on the seasonal plot and a seasonality test result of zero (indicating no significant seasonality), combined with the STL decomposition showing a general upward trajectory, repeating seasonal patterns, and a large spike in the residual component (which cannot be explained by the seasonality), it is concluded that there is no significant seasonal effect on the dataset. Therefore, seasonality adjustment is not necessary.

```{r seasonal adjustment}
# Seasonal plot of real_gdp
library(ggplot2)
ggplot(df_quarterly, aes(x = quarter, y = real_gdp)) +
  geom_line() +
  facet_wrap(~ factor(month(quarter)), scales = "free_y") +
  labs(title = "Seasonal Plot of Real GDP", x = "Quarter", y = "Real GDP")

library(forecast)

# Convert the data to a time series object (quarterly data)
ts_data <- ts(df_quarterly$real_gdp, frequency = 4)

# Test for seasonal differencing
seasonality_test <- nsdiffs(ts_data)

# Print the result
print(seasonality_test)

# Apply STL decomposition
decomp <- stl(ts_data, s.window = "periodic")

# Plot the decomposition to visualize the seasonal component
plot(decomp)
```

## Task 3: Stationarity Testing & Potential Structural Breaks

The Augmented Dickey-Fuller tests for unit roots were conducted with three different regression models: none, drift, and trend. The trend model, which included both a constant and a linear trend, had a test statistic of -2.18, also showing no significant evidence of stationarity, with a p-value of 0.05779. The second model (drift) included a constant, and the test statistic of 1.17 showed no significant evidence of stationarity, with a p-value of 0.2194. Finally, the test statistic was 5.44, which is significant at the 1% level, suggesting the series is stationary. This progression from the most general model (trend) to the simplest model (none) supports the conclusion that the series is stationary.

```{r stationarity with structural break}
library(aTSA)
library(urca)

ts_quarterly <- ts(df_quarterly$real_gdp, start = c(1980, 1), frequency = 4)

# ADF test with constant and trend, specifying 4 lags
adf_trend <- ur.df(ts_quarterly, type = "trend", lags = 4)
summary(adf_trend)

# ADF test with constant (drift), specifying 4 lags
adf_drift <- ur.df(ts_quarterly, type = "drift", lags = 4)
summary(adf_drift)

# ADF test with no constant or trend, specifying 4 lags
adf_none <- ur.df(ts_quarterly, type = "none", lags = 4)  # Specify a valid number of lags
summary(adf_none)
```
## Task 4

```{r stationarity with structural break}
# Assuming df_quarterly is your dataframe and it has a column named 'inflation'
df_quarterly <- df_quarterly %>%
  mutate(inflation_gap = inflation - 2)

# Add a second predictor: lagged value of the time series
df_quarterly <- df_quarterly %>%
  mutate(lagged_inflation = lag(inflation, order_by = quarter))
train_set <- df_quarterly %>% filter(quarter < '2022 Q4')
test_set <- df_quarterly %>% filter(quarter >= '2022 Q4')

# Remove NA values
train_set <- na.omit(train_set)
test_set <- na.omit(test_set)

# Fit the ols with lag model
ols_model <- glm(fed_rate ~ lagged_inflation + inflation_gap + output_gap , data = train_set)

# Fit the ols without lag model
ols_model <- glm(fed_rate ~ inflation_gap + output_gap , data = train_set)

# Predict on the test set
predictions <- predict(ols_model, newdata = test_set)

# Calculate the residuals
residuals <- residuals(ols_model)

# Summarize the model
summary(ols_model)
# Predict on the training set
train_set$Predicted <- predict(ols_model, newdata = train_set)

# Predict on the test set
test_set$Predicted <- predict(ols_model, newdata = test_set)

# Calculate the residuals
residuals <- residuals(ols_model)

# Calculate the RMSE
rmse <- sqrt(mean((train_set$fed_rate - train_set$Predicted)^2))
print(paste("In Sample: Root Mean Squared Error (RMSE):", rmse))
rmse <- sqrt(mean((test_set$fed_rate - test_set$Predicted)^2))
print(paste("Out of Sample: Root Mean Squared Error (RMSE):", rmse))



# Plot the time series and the fitted linear model for the training set
ggplot(train_set, aes(x = quarter)) +
  geom_line(aes(y = fed_rate), color = "black") +
  geom_line(aes(y = Predicted), color = "blue") +
  labs(title = "Linear Model Fit to Time Series Data (Training Set)",
       x = "Time",
       y = "Fed Rate")

# Plot the time series and the fitted linear model for the training set
ggplot(test_set, aes(x = quarter)) +
  geom_line(aes(y = fed_rate), color = "black") +
  geom_line(aes(y = Predicted), color = "blue") +
  labs(title = "Linear Model Fit to Time Series Data (Training Set)",
       x = "Time",
       y = "Fed Rate")

# Calculate the residuals
residuals <- residuals(ols_model)

par(mfrow=c(2,2))

# Plot the residuals using an ACF plot
acf(residuals, main = "ACF of Residuals")
pacf(residuals, main = "PACF of Residuals")
# Plot the histogram of residuals with a normal distribution curve
hist(residuals, breaks = 10, probability = TRUE, main = "Histogram of Residuals with Normal Curve", xlab = "Residuals")
curve(dnorm(x, mean = mean(residuals), sd = sd(residuals)), col = "blue", lwd = 2, add = TRUE, yaxt = "n")
```
According to the https://www.federalreserve.gov/economy-at-a-glance-inflation-pce.htm target inflation is 2%

1. At a parameter alpha0 = 1.89988 and p_value < .05, interest moves more than one for one with inflation. 
Although it does not agree with Taylor's rule, it is worth noting that this model is an oversimplifcation of complex/unpredictable economic variables such as COVID-19
2. In sample RMSE yields 3.27043042498184. 3 percent in interest rates is a not a good sign for the model.
The plot shows that COVID-19 years had a huge impact in the residuals. It may be worth treating COVID-19 data to better the model. Also worth noting is the ACF plot indicates some degree in autocorrelation of the residuals.
3. It is worth mentioning that this is a good prediction of the model as the RSME = 1.37524946670628 is lower in the test set. Evaluating the plot shows the residuals are lessened in comparison to the test data